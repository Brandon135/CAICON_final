{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForObjectDetection\n",
    "\n",
    "# 이미 학습된 모델을 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"C:/Users/fun67/Desktop/lastpj/ckp/ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 데이터셋 로드\n",
    "with open(\"./train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")  # 이미지가 RGB로 변환되도록 보장\n",
    "    image = image.resize(target_size)  # 크기 조정\n",
    "    image = np.array(image).astype(np.float32)  # numpy 배열로 변환 및 float32로 변환\n",
    "    image = image / 255.0  # 정규화\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image)  # torch.Tensor로 변환\n",
    "\n",
    "# COCO 형식으로 변환하는 함수\n",
    "def convert_to_coco_format(data_list):\n",
    "    coco_annotations = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 0, \"name\": \"crack\"},\n",
    "            {\"id\": 1, \"name\": \"pothole\"},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    annotation_id = 1\n",
    "    for idx, data in enumerate(data_list):\n",
    "        coco_annotations[\"images\"].append({\n",
    "            \"file_name\": data[\"image\"],\n",
    "            \"height\": data[\"height\"],\n",
    "            \"width\": data[\"width\"],\n",
    "            \"id\": int(idx)  # int64 -> int 변환\n",
    "        })\n",
    "        \n",
    "        for obj_id, bbox, area, category in zip(data[\"objects\"][\"id\"], data[\"objects\"][\"bbox\"], data[\"objects\"][\"area\"], data[\"objects\"][\"category\"]):\n",
    "            coco_annotations[\"annotations\"].append({\n",
    "                \"image_id\": int(idx),  # int64 -> int 변환\n",
    "                \"category_id\": int(category),  # int64 -> int 변환\n",
    "                \"bbox\": [float(i) for i in bbox],  # bbox 값은 float로 변환\n",
    "                \"area\": float(area),  # area는 float로 변환\n",
    "                \"iscrowd\": 0,  # 일반적으로 0\n",
    "                \"id\": int(annotation_id)  # int64 -> int 변환\n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "    return coco_annotations\n",
    "\n",
    "# 일부 이미지에 대한 mAP 추론을 위한 함수\n",
    "def evaluate_map(model, data_list, num_samples=30):\n",
    "    model.eval()\n",
    "\n",
    "    # 일부 샘플만 사용\n",
    "    selected_samples = data_list[:num_samples]\n",
    "\n",
    "    # COCO 형식으로 변환\n",
    "    coco_annotations = convert_to_coco_format(selected_samples)\n",
    "\n",
    "    # 모델의 예측 결과 저장\n",
    "    all_predictions = []\n",
    "\n",
    "    # COCO 데이터셋 로드 (COCO API)\n",
    "    coco = COCO()\n",
    "    coco.dataset = coco_annotations\n",
    "    coco.createIndex()\n",
    "\n",
    "    # 예측 및 실제 라벨 비교\n",
    "    for idx, sample in enumerate(selected_samples):\n",
    "        image_path = sample[\"image\"]\n",
    "        image = Image.open(image_path)\n",
    "        processed_image = custom_preprocess(image).unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=processed_image)\n",
    "\n",
    "\n",
    "        # 예측된 경계 상자 및 점수 추출 (출력 형식에 맞게 수정)\n",
    "        pred_boxes = outputs[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "        pred_scores = outputs[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "        # 가장 높은 점수를 가진 클래스 선택\n",
    "        for box, scores in zip(pred_boxes, pred_scores):\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "            score = np.max(scores[:-1])  # 배경 클래스 제외\n",
    "\n",
    "            if score > 0:  # 일정 점수 이상일 때만 추가\n",
    "                all_predictions.append({\n",
    "                    \"image_id\": int(idx),  # int64 -> int 변환\n",
    "                    \"category_id\": int(category_id),  # int64 -> int 변환\n",
    "                    \"bbox\": [float(i) for i in box],  # bbox 값은 float로 변환\n",
    "                    \"score\": float(score)  # score는 float로 변환\n",
    "                })\n",
    "\n",
    "    # COCO 포맷으로 예측 저장\n",
    "    with open(\"predictions.json\", \"w\") as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "    # COCO API로 mAP 평가\n",
    "    coco_pred = coco.loadRes(\"predictions.json\")\n",
    "    coco_eval = COCOeval(coco, coco_pred, iouType=\"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "\n",
    "\n",
    "# 5개의 이미지에 대해 mAP를 평가\n",
    "evaluate_map(model, data_list, num_samples=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"C:/Users/fun67/Desktop/lastpj/ckp/ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}  # 각 category_id에 해당하는 라벨 이름\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")  # 정답 상자는 빨간색\n",
    "\n",
    "# 예측 상자 그리기\n",
    "def draw_predictions(image, pred_boxes, pred_scores, id2label, threshold=0.3):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size  # 이미지의 실제 크기 가져오기\n",
    "    for box, scores in zip(pred_boxes, pred_scores):\n",
    "        max_score = np.max(scores)  # 클래스별 점수 중 최대값\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "            \n",
    "            # 모델이 반환하는 좌표를 절대 좌표로 변환 (상대 좌표일 경우)\n",
    "            # 예: 모델 출력이 상대 좌표일 경우, 이미지 크기에 맞춰 변환 필요\n",
    "            x_min, y_min, box_width, box_height = box\n",
    "            x_min *= image_width\n",
    "            y_min *= image_height\n",
    "            box_width *= image_width\n",
    "            box_height *= image_height\n",
    "\n",
    "            x_max = x_min + box_width\n",
    "            y_max = y_min + box_height\n",
    "\n",
    "            draw.rectangle((x_min, y_min, x_max, y_max), outline=\"blue\", width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=\"blue\")  # 예측 상자는 파란색\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 5)  # 이미지 파일에서 랜덤으로 5개 선택\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")  # 라벨 파일은 같은 이름의 .txt 파일\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "    \n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=processed_image)\n",
    "\n",
    "    # 예측된 경계 상자 및 점수 추출\n",
    "    pred_boxes = outputs[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores = outputs[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "\n",
    "    # 예측 상자 그리기 (파란색)\n",
    "    draw_predictions(image, pred_boxes, pred_scores, id2label, threshold=0.3)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#h1 단일 모델 NMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file path: C:/Users/fun67/Desktop/lastpj/data/train/images\\22232a917e1a165ecb378fb3.jpg\n",
      "Label file path: C:/Users/fun67/Desktop/lastpj/data/train/labels\\22232a917e1a165ecb378fb3.txt\n",
      "Boxes before NMS: tensor([[0.3223, 0.3066, 0.5225, 0.8742],\n",
      "        [0.0698, 0.2731, 0.1546, 0.9186],\n",
      "        [0.6759, 0.1309, 0.7004, 0.1649],\n",
      "        ...,\n",
      "        [0.1967, 0.0284, 0.2536, 0.0850],\n",
      "        [0.9593, 0.4394, 0.9893, 0.4758],\n",
      "        [0.1875, 0.3882, 0.2420, 0.4205]])\n",
      "Scores before NMS: [0.9566555  0.8337832  0.9829768  0.92811173 0.8855311  0.79913026\n",
      " 0.9403639  0.9131748  0.9711592  0.9492621  0.9633989  0.8704058\n",
      " 0.9156393  0.99446714 0.95218843 0.67683095 0.9375367  0.8925924\n",
      " 0.88898647 0.9004191  0.8502052  0.89624494 0.90779346 0.94502115\n",
      " 0.9215011  0.9009004  0.8059885  0.85028344 0.89495975 0.83309114\n",
      " 0.7559803  0.92277133 0.84793174 0.7726171  0.9500346  0.95296675\n",
      " 0.9056214  0.8789002  0.910765   0.9253096  0.8743888  0.9398338\n",
      " 0.9543219  0.89949733 0.73579067 0.74725974 0.91748345 0.9281157\n",
      " 0.9009247  0.79948443 0.93893343 0.8901273  0.9165871  0.874206\n",
      " 0.89277506 0.82609814 0.92952317 0.92614627 0.930427   0.81274575\n",
      " 0.9340133  0.7868279  0.85067564 0.81091833 0.85644764 0.9332398\n",
      " 0.88956076 0.7665715  0.9045465  0.92582196 0.7525139  0.82857007\n",
      " 0.8971336  0.93189204 0.80413175 0.8797362  0.8663594  0.8536658\n",
      " 0.7899334  0.8207462  0.94029975 0.8883031  0.91267824 0.9171785\n",
      " 0.74119633 0.8480202  0.76129967 0.8960409  0.9025446  0.860225\n",
      " 0.79329926 0.81853384 0.9064107  0.90635085 0.86042166 0.9059655\n",
      " 0.8037354  0.9440999  0.90895337 0.84506136 0.6624554  0.78065604\n",
      " 0.89912945 0.740709   0.92113584 0.841377   0.7286503  0.77041906\n",
      " 0.93696374 0.87932646 0.7927361  0.7836349  0.7138156  0.9066284\n",
      " 0.68884426 0.9462682  0.9146061  0.8899569  0.89377666 0.9197179\n",
      " 0.76418084 0.80042547 0.9020604  0.7748606  0.8137693  0.8977367\n",
      " 0.8223383  0.9239622  0.70771086 0.77970004 0.892997   0.86726296\n",
      " 0.81592786 0.8175652  0.83535314 0.78117615 0.86178124 0.8794813\n",
      " 0.9085638  0.9552354  0.91739696 0.91937286 0.9185382  0.8178002\n",
      " 0.84263223 0.9310488  0.936129   0.7737973  0.88546646 0.7411737\n",
      " 0.79792345 0.88945806 0.7053143  0.86404353 0.7775968  0.9187526\n",
      " 0.91370213 0.7767593  0.7743507  0.91382873 0.84510994 0.79614747\n",
      " 0.85625684 0.8611214  0.7989604  0.6750705  0.8565808  0.7935968\n",
      " 0.89081633 0.8402921  0.9197895  0.7575877  0.880858   0.8255558\n",
      " 0.93095475 0.73925716 0.8815687  0.786426   0.7314291  0.77035356\n",
      " 0.82022214 0.71676296 0.8995625  0.8821755  0.84672016 0.77679926\n",
      " 0.81055045 0.7573674  0.90561086 0.7540398  0.7504349  0.9408714\n",
      " 0.81800497 0.62733996 0.74902153 0.81828034 0.8330873  0.8111303\n",
      " 0.9402652  0.8074377  0.8943914  0.73689866 0.9424234  0.94496787\n",
      " 0.8021207  0.87137574 0.8892396  0.7872934  0.8268687  0.9115455\n",
      " 0.85055846 0.8039058  0.82500786 0.7147997  0.86561185 0.93369436\n",
      " 0.8358239  0.8771141  0.8933183  0.7439588  0.8342633  0.8553842\n",
      " 0.79297733 0.926917   0.9055216  0.8274517  0.79526424 0.892669\n",
      " 0.93812126 0.87946475 0.7986408  0.7719675  0.7439037  0.8573041\n",
      " 0.8571927  0.7745699  0.7267389  0.92199445 0.83848983 0.9093367\n",
      " 0.67688024 0.7796762  0.81356966 0.9181257  0.8493994  0.841636\n",
      " 0.8961911  0.7693537  0.84374386 0.8569625  0.8031783  0.7890142\n",
      " 0.7932018  0.7843576  0.7052626  0.83777654 0.75237054 0.82607293\n",
      " 0.7799947  0.86059374 0.7263476  0.85844934 0.81952006 0.81516194\n",
      " 0.8876782  0.7972168  0.8206098  0.7037896  0.856423   0.8080284\n",
      " 0.86138207 0.82053673 0.8304133  0.8937978  0.77146834 0.74248475\n",
      " 0.89934766 0.8499961  0.7480767  0.7823025  0.88851094 0.75028867\n",
      " 0.85950184 0.8599069  0.85464466 0.8779583  0.8072462  0.84312594\n",
      " 0.81719095 0.7311613  0.8165063  0.8246762  0.7844534  0.8807527\n",
      " 0.76080275 0.8086955  0.8970453  0.775837   0.7038548  0.7072035 ]\n",
      "Kept indices after NMS: tensor([ 13,   2,   8,  10,   0, 139,  42,  35,  14,  34,   9, 115,  23, 203,\n",
      "         97, 202, 191,   6,  80, 198,  41,  50, 228,  16, 108, 146,  60, 215,\n",
      "         65,  73, 145, 174,  58,  56,  47,   3, 223,  57,  69,  39, 127,  31,\n",
      "        237,  24, 104, 170, 119, 141, 155, 142, 243,  46, 140,  83,  52,  12,\n",
      "        116, 159, 156,   7,  82, 209,  38, 239,  98, 138,  22, 113,  92,  93,\n",
      "         95,  36, 188, 224,  68,  88, 122,  48,  25,  19, 182,  43, 276, 102,\n",
      "        125,  72, 296,  21, 246,  87,  28, 200, 273, 118, 218, 130,  54, 227,\n",
      "         17, 168,  51, 117,  66, 151, 206,  18, 280,  81, 264,   4, 148, 183,\n",
      "        176, 172, 293,  75, 137, 229, 109,  37, 285, 217,  40,  53, 205,  11,\n",
      "        131,  76, 214, 153, 136, 270, 163, 259,  94,  89, 283, 282, 261, 233,\n",
      "        234, 249, 166,  64, 268, 162, 221, 284,  77,  62, 210,  27,  20, 277,\n",
      "        244,  85,  32, 184, 160,  99, 248, 287, 144, 245, 105, 169, 238, 255,\n",
      "        216, 134, 220,   1,  29, 196, 272,  71, 225, 208,  55, 257, 173, 212,\n",
      "        291, 126,  79, 266, 271, 180, 262,  91, 195, 192, 143, 133, 288, 290,\n",
      "        132, 263, 124, 242,  59, 197,  63, 186, 295, 269, 199, 286,  26,  74,\n",
      "        211,  96, 250, 204, 121,  49,   5, 164, 230, 150, 265, 161, 226, 167,\n",
      "         90, 252, 222, 110,  78, 251, 207,  61, 177, 292, 253, 111, 279, 135,\n",
      "        101, 258, 129, 241, 154, 185, 157, 297, 123, 235, 158, 147,  33, 231,\n",
      "        274, 107, 179, 247,  67, 120,  86, 294, 171, 187,  30, 189,  70, 256,\n",
      "        190, 281, 194, 278,  45, 219, 232, 275,  84, 149, 103, 175, 201,  44,\n",
      "        178, 289, 106, 236, 260, 181, 213, 112, 128, 299, 152, 254, 298, 267,\n",
      "        114, 240,  15, 165, 100, 193])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"ckp/ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리 id2label\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}  # 각 category_id에 해당하는 라벨 이름\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")  # 정답 상자는 빨간색\n",
    "\n",
    "# NMS 적용 함수\n",
    "def apply_nms(pred_boxes, pred_scores, iou_threshold=0.5):\n",
    "    # 최대 점수와 상응하는 클래스 id를 가져옴\n",
    "    scores = np.max(pred_scores[:, :-1], axis=1)  # 배경 클래스 제외\n",
    "    boxes = torch.tensor(pred_boxes)  # 예측된 박스 (x_min, y_min, w, h)\n",
    "    \n",
    "    # (x_min, y_min, x_max, y_max) 형식으로 변환\n",
    "    pred_boxes_xyxy = torch.zeros_like(boxes)\n",
    "    pred_boxes_xyxy[:, 0] = boxes[:, 0]  # x_min\n",
    "    pred_boxes_xyxy[:, 1] = boxes[:, 1]  # y_min\n",
    "    pred_boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]  # x_max = x_min + width\n",
    "    pred_boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]  # y_max = y_min + height\n",
    "\n",
    "    print(\"Boxes before NMS:\", pred_boxes_xyxy)\n",
    "    print(\"Scores before NMS:\", scores)\n",
    "\n",
    "    # NMS 적용 (iou_threshold는 겹치는 비율의 임계값)\n",
    "    keep_indices = torchvision.ops.nms(pred_boxes_xyxy, torch.tensor(scores), iou_threshold)\n",
    "    \n",
    "    print(\"Kept indices after NMS:\", keep_indices)\n",
    "\n",
    "    # NMS 결과 반환 (필터링된 상자 및 점수)\n",
    "    return pred_boxes[keep_indices], pred_scores[keep_indices]\n",
    "\n",
    "# 예측 상자 그리기 (NMS 적용 후)\n",
    "# 예측 상자 그리기 (NMS 적용 후)\n",
    "def draw_predictions_with_nms(image, pred_boxes, pred_scores, id2label, threshold=0.1, iou_threshold=0.1):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # NMS 적용\n",
    "    filtered_boxes, filtered_scores = apply_nms(pred_boxes, pred_scores, iou_threshold)\n",
    "\n",
    "    for box, scores in zip(filtered_boxes, filtered_scores):\n",
    "        max_score = np.max(scores)\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "\n",
    "            # 예측 상자 변환 (YOLO 형식처럼)\n",
    "            x_min, y_min, box_width, box_height = box\n",
    "\n",
    "            # 좌표 변환 (중앙 좌표와 크기로부터 좌상단과 우하단 좌표 계산)\n",
    "            x_center = x_min\n",
    "            y_center = y_min\n",
    "            x_min = (x_center - box_width / 2) * image_width\n",
    "            y_min = (y_center - box_height / 2) * image_height\n",
    "            x_max = (x_center + box_width / 2) * image_width\n",
    "            y_max = (y_center + box_height / 2) * image_height\n",
    "\n",
    "            # 파란색으로 예측 상자 그리기\n",
    "            draw.rectangle((x_min, y_min, x_max, y_max), outline=\"blue\", width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=\"blue\")\n",
    "\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 1)  # 이미지 파일에서 랜덤으로 5개 선택\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")  # 라벨 파일은 같은 이름의 .txt 파일\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "    \n",
    "    # 원본 파일 경로 출력\n",
    "    print(f\"Image file path: {image_file}\")\n",
    "    print(f\"Label file path: {label_file}\")\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=processed_image)\n",
    "\n",
    "    # 예측된 경계 상자 및 점수 추출\n",
    "    pred_boxes = outputs[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores = outputs[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "\n",
    "    # 예측 상자 그리기 (NMS 적용하여 파란색 상자만 표시)\n",
    "    draw_predictions_with_nms(image, pred_boxes, pred_scores, id2label, threshold=0.5, iou_threshold=0.97)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMS한거 안한거 단일 파일 이미지 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file path: C:/Users/fun67/Desktop/lastpj/data/train/images\\ef9b949862519c483bf850c1.jpg\n",
      "Label file path: C:/Users/fun67/Desktop/lastpj/data/train/labels\\ef9b949862519c483bf850c1.txt\n",
      "Displaying image without NMS:\n",
      "Displaying image with NMS:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"ckp/ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리 id2label\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")\n",
    "\n",
    "# NMS 적용 함수\n",
    "def apply_nms(pred_boxes, pred_scores, iou_threshold=0.5):\n",
    "    # 최대 점수와 상응하는 클래스 id를 가져옴\n",
    "    scores = np.max(pred_scores[:, :-1], axis=1)  # 배경 클래스 제외\n",
    "    boxes = torch.tensor(pred_boxes)  # 예측된 박스 (x_min, y_min, w, h)\n",
    "\n",
    "    # (x_min, y_min, x_max, y_max) 형식으로 변환\n",
    "    pred_boxes_xyxy = torch.zeros_like(boxes)\n",
    "    pred_boxes_xyxy[:, 0] = boxes[:, 0]  # x_min\n",
    "    pred_boxes_xyxy[:, 1] = boxes[:, 1]  # y_min\n",
    "    pred_boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]  # x_max = x_min + width\n",
    "    pred_boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]  # y_max = y_min + height\n",
    "\n",
    "    # NMS 적용 (iou_threshold는 겹치는 비율의 임계값)\n",
    "    keep_indices = torchvision.ops.nms(pred_boxes_xyxy, torch.tensor(scores), iou_threshold)\n",
    "\n",
    "    # NMS 결과 반환 (필터링된 상자 및 점수)\n",
    "    return pred_boxes[keep_indices], pred_scores[keep_indices]\n",
    "\n",
    "# 예측 상자 그리기 (NMS 적용 후)\n",
    "def draw_predictions_with_nms(image, pred_boxes, pred_scores, id2label, threshold=0.1, iou_threshold=0.9):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # NMS 적용\n",
    "    filtered_boxes, filtered_scores = apply_nms(pred_boxes, pred_scores, iou_threshold)\n",
    "\n",
    "    for box, scores in zip(filtered_boxes, filtered_scores):\n",
    "        max_score = np.max(scores)\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "\n",
    "            # 예측 상자 변환 (YOLO 형식처럼)\n",
    "            x_min, y_min, box_width, box_height = box\n",
    "\n",
    "            # 좌표 변환 (중앙 좌표와 크기로부터 좌상단과 우하단 좌표 계산)\n",
    "            x_center = x_min\n",
    "            y_center = y_min\n",
    "            x_min = (x_center - box_width / 2) * image_width\n",
    "            y_min = (y_center - box_height / 2) * image_height\n",
    "            x_max = (x_center + box_width / 2) * image_width\n",
    "            y_max = (y_center + box_height / 2) * image_height\n",
    "\n",
    "            # 파란색으로 예측 상자 그리기\n",
    "            draw.rectangle((x_min, y_min, x_max, y_max), outline=\"blue\", width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=\"blue\")\n",
    "\n",
    "# 예측 상자 그리기 (NMS 미적용)\n",
    "def draw_predictions_without_nms(image, pred_boxes, pred_scores, id2label, threshold=0.9):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    for box, scores in zip(pred_boxes, pred_scores):\n",
    "        max_score = np.max(scores)\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "\n",
    "            # 예측 상자 변환 (YOLO 형식처럼)\n",
    "            x_min, y_min, box_width, box_height = box\n",
    "\n",
    "            # 좌표 변환 (중앙 좌표와 크기로부터 좌상단과 우하단 좌표 계산)\n",
    "            x_center = x_min\n",
    "            y_center = y_min\n",
    "            x_min = (x_center - box_width / 2) * image_width\n",
    "            y_min = (y_center - box_height / 2) * image_height\n",
    "            x_max = (x_center + box_width / 2) * image_width\n",
    "            y_max = (y_center + box_height / 2) * image_height\n",
    "\n",
    "            # 녹색으로 예측 상자 그리기 (NMS 없이)\n",
    "            draw.rectangle((x_min, y_min, x_max, y_max), outline=\"green\", width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=\"green\")\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 1)  # 이미지 파일에서 랜덤으로 5개 선택\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")  # 라벨 파일은 같은 이름의 .txt 파일\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "\n",
    "    # 원본 파일 경로 출력\n",
    "    print(f\"Image file path: {image_file}\")\n",
    "    print(f\"Label file path: {label_file}\")\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "\n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=processed_image)\n",
    "\n",
    "    # 예측된 경계 상자 및 점수 추출\n",
    "    pred_boxes = outputs[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores = outputs[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "\n",
    "    # 예측 상자 그리기 (NMS 미적용, 녹색 상자)\n",
    "    image_without_nms = image.copy()\n",
    "    draw_predictions_without_nms(image_without_nms, pred_boxes, pred_scores, id2label, threshold=0.95)\n",
    "\n",
    "    # 예측 상자 그리기 (NMS 적용하여 파란색 상자만 표시)\n",
    "    image_with_nms = image.copy()\n",
    "    draw_predictions_with_nms(image_with_nms, pred_boxes, pred_scores, id2label, threshold=0.5, iou_threshold=0.97)\n",
    "\n",
    "    # NMS 없이 이미지 출력\n",
    "    print(\"Displaying image without NMS:\")\n",
    "    image_without_nms.show()\n",
    "\n",
    "    # NMS 적용된 이미지 출력\n",
    "    print(\"Displaying image with NMS:\")\n",
    "    image_with_nms.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 두 개의 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 기존 모델\n",
    "model_old = AutoModelForObjectDetection.from_pretrained(\n",
    "    r\"C:\\Users\\fun67\\Desktop\\lastpj\\ckp\\ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# 새로운 모델\n",
    "model_new = AutoModelForObjectDetection.from_pretrained(\n",
    "    r\"C:\\Users\\fun67\\Desktop\\lastpj\\ckp\\ckpt_rtdetr_r50vd_1epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}  # 각 category_id에 해당하는 라벨 이름\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")  # 정답 상자는 빨간색\n",
    "\n",
    "# 모델 예측 상자 그리기 (각 모델마다 다른 색상)\n",
    "# 모델 예측 상자 그리기 (각 모델마다 다른 색상)\n",
    "def draw_predictions(image, pred_boxes, pred_scores, id2label, color=\"blue\", threshold=0.96):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size  # 이미지의 실제 크기 가져오기\n",
    "\n",
    "    for box, scores in zip(pred_boxes, pred_scores):\n",
    "        max_score = np.max(scores)  # 클래스별 점수 중 최대값\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "            \n",
    "            # 모델이 반환하는 좌표가 (x_center, y_center, width, height) 형식일 경우\n",
    "            x_center, y_center, box_width, box_height = box\n",
    "            \n",
    "            # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "            x_center *= image_width\n",
    "            y_center *= image_height\n",
    "            box_width *= image_width\n",
    "            box_height *= image_height\n",
    "\n",
    "            x_min = x_center - (box_width / 2)\n",
    "            y_min = y_center - (box_height / 2)\n",
    "            x_max = x_center + (box_width / 2)\n",
    "            y_max = y_center + (box_height / 2)\n",
    "\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=color)\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 5)  # 이미지 파일에서 랜덤으로 5개 선택\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")  # 라벨 파일은 같은 이름의 .txt 파일\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 기존 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_old = model_old(pixel_values=processed_image)\n",
    "\n",
    "    # 새로운 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_new = model_new(pixel_values=processed_image)\n",
    "\n",
    "    # 기존 모델의 예측 경계 상자 및 점수 추출\n",
    "    pred_boxes_old = outputs_old[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores_old = outputs_old[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "    # 새로운 모델의 예측 경계 상자 및 점수 추출\n",
    "    pred_boxes_new = outputs_new[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores_new = outputs_new[\"logits\"].softmax(-1)[0].cpu().numpy()  # 클래스 점수\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "    Vth = 0.92\n",
    "    # 기존 모델의 예측 상자 그리기 (파란색)\n",
    "    draw_predictions(image, pred_boxes_old, pred_scores_old, id2label, color=\"blue\", threshold=Vth)\n",
    "\n",
    "    # 새로운 모델의 예측 상자 그리기 (초록색)\n",
    "    draw_predictions(image, pred_boxes_new, pred_scores_new, id2label, color=\"green\", threshold=Vth)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    image.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#다중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b53dac1763d49078be442e9e.jpg - mAP (Old Model): 99.6667, mAP (New Model): 99.6667\n",
      "adc8bb32d8b0089a2f82eec1.jpg - mAP (Old Model): 37.3750, mAP (New Model): 37.3750\n",
      "dda4f68c18e5e33eeaaeb37b.jpg - mAP (Old Model): 99.6667, mAP (New Model): 99.6667\n",
      "da0c573d1a9f291c7d9951ec.jpg - mAP (Old Model): 299.0000, mAP (New Model): 299.0000\n",
      "bab047c1dbc3abb60b3d5ca5.jpg - mAP (Old Model): 149.5000, mAP (New Model): 149.5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "\n",
    "iouval = 0\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 두 개의 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 기존 모델\n",
    "model_old = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"ckp/ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# 새로운 모델\n",
    "model_new = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"ckp/ckpt_rtdetr_r50vd_n71epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}  # 각 category_id에 해당하는 라벨 이름\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")  # 정답 상자는 빨간색\n",
    "\n",
    "# 모델 예측 상자 그리기 (각 모델마다 다른 색상)\n",
    "def draw_predictions(image, pred_boxes, pred_scores, id2label, color=\"blue\", threshold=0.96):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size  # 이미지의 실제 크기 가져오기\n",
    "    for box, scores in zip(pred_boxes, pred_scores):\n",
    "        max_score = np.max(scores)  # 클래스별 점수 중 최대값\n",
    "        if max_score > threshold:\n",
    "            category_id = np.argmax(scores[:-1])  # 배경 클래스 제외\n",
    "            \n",
    "            # 모델이 반환하는 좌표를 절대 좌표로 변환 (상대 좌표일 경우)\n",
    "            x_min, y_min, box_width, box_height = box\n",
    "            x_min *= image_width\n",
    "            y_min *= image_height\n",
    "            box_width *= image_width\n",
    "            box_height *= image_height\n",
    "\n",
    "            x_max = x_min + box_width\n",
    "            y_max = y_min + box_height\n",
    "\n",
    "            draw.rectangle((x_min, y_min, x_max, y_max), outline=color, width=2)\n",
    "            draw.text((x_min, y_min), id2label[category_id], fill=color)  # 예측 상자를 해당 색상으로\n",
    "\n",
    "# IoU 계산 함수\n",
    "def compute_iou(box1, box2):\n",
    "    # box1, box2: (x_min, y_min, x_max, y_max) 형식의 경계 상자\n",
    "    x_min1, y_min1, x_max1, y_max1 = box1\n",
    "    x_min2, y_min2, x_max2, y_max2 = box2\n",
    "\n",
    "    # 교차 영역의 좌상단, 우하단 좌표\n",
    "    inter_x_min = max(x_min1, x_min2)\n",
    "    inter_y_min = max(y_min1, y_min2)\n",
    "    inter_x_max = min(x_max1, x_max2)\n",
    "    inter_y_max = min(y_max1, y_max2)\n",
    "\n",
    "    # 교차 영역의 너비와 높이\n",
    "    inter_w = max(0, inter_x_max - inter_x_min)\n",
    "    inter_h = max(0, inter_y_max - inter_y_min)\n",
    "\n",
    "    # 교차 영역의 면적\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # 두 상자의 면적 계산\n",
    "    box1_area = (x_max1 - x_min1) * (y_max1 - y_min1)\n",
    "    box2_area = (x_max2 - x_min2) * (y_max2 - y_min2)\n",
    "\n",
    "    # IoU 계산 (교차 영역 / (두 상자의 합에서 교차 영역을 뺀 값))\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area if union_area != 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "# AP 계산 함수\n",
    "def calculate_ap(pred_boxes, pred_scores, gt_boxes, iou_threshold=iouval):\n",
    "    sorted_indices = np.argsort(-pred_scores)\n",
    "    pred_boxes = pred_boxes[sorted_indices]\n",
    "\n",
    "    tp = np.zeros(len(pred_boxes))\n",
    "    fp = np.zeros(len(pred_boxes))\n",
    "    matched = []\n",
    "\n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        max_iou = 0\n",
    "        matched_gt_idx = -1\n",
    "        for j, gt_box in enumerate(gt_boxes):\n",
    "            if j not in matched:\n",
    "                iou = compute_iou(pred_box, gt_box)\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_gt_idx = j\n",
    "        \n",
    "        if max_iou >= iou_threshold:\n",
    "            tp[i] = 1\n",
    "            matched.append(matched_gt_idx)\n",
    "        else:\n",
    "            fp[i] = 1\n",
    "\n",
    "    # 누적 True Positive와 False Positive\n",
    "    tp_cumsum = np.cumsum(tp)\n",
    "    fp_cumsum = np.cumsum(fp)\n",
    "\n",
    "    precision = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
    "    recall = tp_cumsum / len(gt_boxes)\n",
    "\n",
    "    ap = np.sum((recall[1:] - recall[:-1]) * precision[1:])  # AP 계산\n",
    "\n",
    "    return ap\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 5)  # 이미지 파일에서 랜덤으로 5개 선택\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 기존 모델 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_old = model_old(pixel_values=processed_image)\n",
    "\n",
    "    # 새로운 모델 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_new = model_new(pixel_values=processed_image)\n",
    "\n",
    "    # 예측 경계 상자 및 점수\n",
    "    pred_boxes_old = outputs_old[\"pred_boxes\"][0].cpu().numpy()\n",
    "    pred_scores_old = outputs_old[\"logits\"].softmax(-1)[0].cpu().numpy()\n",
    "\n",
    "    pred_boxes_new = outputs_new[\"pred_boxes\"][0].cpu().numpy()\n",
    "    pred_scores_new = outputs_new[\"logits\"].softmax(-1)[0].cpu().numpy()\n",
    "\n",
    "    # 정답 경계 상자 로드\n",
    "    gt_boxes = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "        for label in labels:\n",
    "            class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "            x_min = x_center - (box_width / 2)\n",
    "            y_min = y_center - (box_height / 2)\n",
    "            x_max = x_center + (box_width / 2)\n",
    "            y_max = y_center + (box_height / 2)\n",
    "            gt_boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # mAP 계산 (기존 모델)\n",
    "    ap_old = calculate_ap(pred_boxes_old, pred_scores_old[:, :-1].max(axis=1), gt_boxes, iou_threshold=iouval)\n",
    "\n",
    "    # mAP 계산 (새 모델)\n",
    "    ap_new = calculate_ap(pred_boxes_new, pred_scores_new[:, :-1].max(axis=1), gt_boxes, iou_threshold=iouval)\n",
    "\n",
    "    print(f\"{image_file_name} - mAP (Old Model): {ap_old:.4f}, mAP (New Model): {ap_new:.4f}\")\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "    Vth = 0.92\n",
    "    # 기존 모델의 예측 상자 그리기 (파란색)\n",
    "    draw_predictions(image, pred_boxes_old, pred_scores_old, id2label, color=\"blue\", threshold=Vth)\n",
    "\n",
    "    # 새로운 모델의 예측 상자 그리기 (초록색)\n",
    "    draw_predictions(image, pred_boxes_new, pred_scores_new, id2label, color=\"green\", threshold=Vth)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid box: (0.082807064, 0.37776, 0.12791897, 0.22509557)\n",
      "Invalid box: (0.049391948, 0.15486304, 0.101005435, 0.09452658)\n",
      "Invalid box: (0.45633823, 0.3862209, 0.31349543, 0.54638654)\n",
      "Invalid box: (0.080100544, 0.8028721, 0.15504864, 0.19185144)\n",
      "Invalid box: (0.22195293, 0.5200341, 0.4439971, 0.044366367)\n",
      "Invalid box: (0.12922998, 0.8493648, 0.056174714, 0.09817126)\n",
      "Invalid box: (0.052536696, 0.7536015, 0.10236366, 0.0965512)\n",
      "Invalid box: (0.79590523, 0.38962007, 0.072790995, 0.009856649)\n",
      "Invalid box: (0.20135707, 0.13629088, 0.18739448, 0.0074338177)\n",
      "Invalid box: (0.11482073, 0.5329275, 0.22793204, 0.020217948)\n",
      "Invalid box: (0.17671977, 0.55657476, 0.014161417, 0.04917904)\n",
      "Invalid box: (0.09442226, 0.80976, 0.12214617, 0.17619342)\n",
      "Invalid box: (0.72727525, 0.34020004, 0.05858771, 0.0074990666)\n",
      "Invalid box: (0.20150556, 0.7418025, 0.13736217, 0.08059214)\n",
      "Invalid box: (0.7293525, 0.3408386, 0.054283194, 0.0071410476)\n",
      "Invalid box: (0.14383672, 0.7789399, 0.023999646, 0.0075286455)\n",
      "Invalid box: (0.7082805, 0.8659554, 0.045661528, 0.10165677)\n",
      "Invalid box: (0.791906, 0.38982892, 0.06230846, 0.008228147)\n",
      "Invalid box: (0.3691497, 0.27359554, 0.13454086, 0.31640163)\n",
      "Invalid box: (0.6747363, 0.790766, 0.11050175, 0.24815786)\n",
      "Invalid box: (0.012846195, 0.4915754, 0.024409998, 0.014522423)\n",
      "Invalid box: (0.09107069, 0.53253317, 0.17990625, 0.020898636)\n",
      "Invalid box: (0.5827957, 0.6583498, 0.06357663, 0.0063026384)\n",
      "Invalid box: (0.06118521, 0.7567221, 0.08649304, 0.08996418)\n",
      "Invalid box: (0.3454895, 0.510305, 0.19315524, 0.02461051)\n",
      "Invalid box: (0.6064378, 0.661808, 0.019859202, 0.0067227436)\n",
      "Invalid box: (0.087825865, 0.801344, 0.039770517, 0.008335041)\n",
      "Invalid box: (0.38509026, 0.5048988, 0.10659724, 0.013240453)\n",
      "Invalid box: (0.14811726, 0.88410693, 0.018007876, 0.031357065)\n",
      "Invalid box: (0.012405078, 0.5420092, 0.024228074, 0.0065495735)\n",
      "Invalid box: (0.5635689, 0.6486757, 0.10193186, 0.026135143)\n",
      "Invalid box: (0.72251016, 0.89581233, 0.017784454, 0.04434665)\n",
      "Invalid box: (0.5264469, 0.55082643, 0.17261527, 0.21868649)\n",
      "Invalid box: (0.21474648, 0.5276401, 0.03297342, 0.005545566)\n",
      "Invalid box: (0.40623477, 0.37347975, 0.20519942, 0.5266307)\n",
      "Invalid box: (0.122094765, 0.8485246, 0.07076666, 0.09959185)\n",
      "Invalid box: (0.026980257, 0.17698805, 0.05588142, 0.047850817)\n",
      "Invalid box: (0.7085635, 0.86769474, 0.045868337, 0.100504786)\n",
      "Invalid box: (0.048634302, 0.5335283, 0.093519755, 0.019610053)\n",
      "Invalid box: (0.14775173, 0.8798145, 0.01882857, 0.037511252)\n",
      "Invalid box: (0.22401655, 0.74081355, 0.087802276, 0.07425983)\n",
      "Invalid box: (0.9593728, 0.6962062, 0.037868313, 0.041501366)\n",
      "Invalid box: (0.16970618, 0.5259405, 0.120889425, 0.008773571)\n",
      "Invalid box: (0.71944267, 0.8907864, 0.02401612, 0.05279121)\n",
      "Invalid box: (0.120156914, 0.8477771, 0.06515368, 0.09702896)\n",
      "Invalid box: (0.7894774, 0.38921624, 0.054069713, 0.0066703344)\n",
      "Invalid box: (0.19974856, 0.55324584, 0.06077846, 0.05619214)\n",
      "Invalid box: (0.6062108, 0.6621304, 0.019897807, 0.0061655315)\n",
      "Invalid box: (0.028910479, 0.27081934, 0.045803756, 0.04923409)\n",
      "Invalid box: (0.6723521, 0.7916746, 0.11092963, 0.25046465)\n",
      "Invalid box: (0.08091695, 0.10693394, 0.040561546, 0.006043348)\n",
      "Invalid box: (0.37464234, 0.29017136, 0.14418754, 0.34470338)\n",
      "Invalid box: (0.13547057, 0.29256442, 0.02476248, 0.055479497)\n",
      "Invalid box: (0.772832, 0.38678083, 0.028855596, 0.005143804)\n",
      "Invalid box: (0.3543691, 0.16064698, 0.02731442, 0.028209737)\n",
      "Invalid box: (0.33924302, 0.17605282, 0.058406677, 0.05954266)\n",
      "Invalid box: (0.3578282, 0.15848614, 0.1005833, 0.10557364)\n",
      "Invalid box: (0.32679674, 0.18959618, 0.085017495, 0.08796119)\n",
      "Invalid box: (0.36093327, 0.15228917, 0.088596486, 0.09368849)\n",
      "Invalid box: (0.39128035, 0.15819962, 0.20966701, 0.15364574)\n",
      "Invalid box: (0.40181676, 0.15372473, 0.20874134, 0.14187291)\n",
      "Invalid box: (0.43651316, 0.07497125, 0.1430929, 0.02155546)\n",
      "Invalid box: (0.5155688, 0.086655445, 0.010346754, 0.0722218)\n",
      "Invalid box: (0.47489414, 0.082315534, 0.06661485, 0.0056276815)\n",
      "Invalid box: (0.39371082, 0.12005907, 0.027899826, 0.027222436)\n",
      "Invalid box: (0.33683962, 0.3664161, 0.062358297, 0.5493671)\n",
      "Invalid box: (0.32598385, 0.456673, 0.08367638, 0.7354526)\n",
      "Invalid box: (0.24616641, 0.32669434, 0.15651448, 0.07775497)\n",
      "Invalid box: (0.2691765, 0.16361845, 0.08589113, 0.1481666)\n",
      "Invalid box: (0.2564218, 0.18616, 0.10994386, 0.19378608)\n",
      "Invalid box: (0.2953025, 0.11964535, 0.033777997, 0.061514936)\n",
      "Invalid box: (0.3548512, 0.08989975, 0.025846101, 0.006742182)\n",
      "Invalid box: (0.45479497, 0.08659945, 0.0533957, 0.1501182)\n",
      "Invalid box: (0.37206423, 0.039277785, 0.0823995, 0.0038937165)\n",
      "Invalid box: (0.34164712, 0.088856325, 0.050797366, 0.00810416)\n",
      "Invalid box: (0.019189937, 0.33969557, 0.03703915, 0.04001368)\n",
      "Invalid box: (0.23485447, 0.22776367, 0.019821446, 0.025464704)\n",
      "Invalid box: (0.31771994, 0.5215019, 0.022374045, 0.23866946)\n",
      "Invalid box: (0.3085144, 0.61505276, 0.04306854, 0.41827595)\n",
      "Invalid box: (0.3085839, 0.61527014, 0.041714873, 0.41641074)\n",
      "Invalid box: (0.34108326, 0.08853778, 0.051533315, 0.008079491)\n",
      "Invalid box: (0.46857587, 0.13271552, 0.021988738, 0.052226193)\n",
      "Invalid box: (0.4553895, 0.0813408, 0.05543853, 0.15205935)\n",
      "Invalid box: (0.09360619, 0.52278924, 0.17952633, 0.3264863)\n",
      "Invalid box: (0.35149282, 0.21116698, 0.03348413, 0.2337456)\n",
      "Invalid box: (0.3696247, 0.6442952, 0.11762985, 0.007185268)\n",
      "Invalid box: (0.40747085, 0.6430899, 0.045207623, 0.0060419757)\n",
      "Invalid box: (0.36135364, 0.14378986, 0.014505829, 0.09839049)\n",
      "Invalid box: (0.38450855, 0.060384467, 0.060495585, 0.004204429)\n",
      "Invalid box: (0.28890407, 0.13041684, 0.021851975, 0.039211422)\n",
      "Invalid box: (0.32167923, 0.120882735, 0.09197846, 0.068486124)\n",
      "Invalid box: (0.2381925, 0.22545314, 0.016724939, 0.025156949)\n",
      "Invalid box: (0.09436602, 0.5138709, 0.14912513, 0.30363494)\n",
      "Invalid box: (0.3670018, 0.05994078, 0.09635038, 0.004525982)\n",
      "Invalid box: (0.28696254, 0.13705087, 0.044386376, 0.09549677)\n",
      "Invalid box: (0.37250206, 0.03933562, 0.081637755, 0.00388027)\n",
      "Invalid box: (0.37437713, 0.03964255, 0.077183425, 0.0034329288)\n",
      "Invalid box: (0.28153396, 0.14546876, 0.031514317, 0.06446241)\n",
      "Invalid box: (0.11287396, 0.39269, 0.032220904, 0.014839971)\n",
      "Invalid box: (0.35727444, 0.16091333, 0.022179708, 0.13503723)\n",
      "Invalid box: (0.32880613, 0.060252212, 0.021423092, 0.0062903943)\n",
      "Invalid box: (0.18558115, 0.3628538, 0.033028655, 0.007357396)\n",
      "Invalid box: (0.23673083, 0.22787459, 0.015043441, 0.023268629)\n",
      "Invalid box: (0.18577036, 0.36333793, 0.032403618, 0.0076716663)\n",
      "Invalid box: (0.104570724, 0.20436776, 0.20698757, 0.11243172)\n",
      "Invalid box: (0.48578098, 0.53564894, 0.030635823, 0.64613414)\n",
      "Invalid box: (0.48912013, 0.35322827, 0.022766728, 0.28785664)\n",
      "Invalid box: (0.14893392, 0.17921802, 0.11384572, 0.060758203)\n",
      "Invalid box: (0.4878353, 0.3885865, 0.020236319, 0.20412356)\n",
      "Invalid box: (0.19418338, 0.037440863, 0.021567773, 0.07122072)\n",
      "Invalid box: (0.48617288, 0.48825777, 0.02590849, 0.46869147)\n",
      "Invalid box: (0.48567045, 0.4319407, 0.023859255, 0.29263735)\n",
      "Invalid box: (0.08730136, 0.111190915, 0.16491869, 0.035627693)\n",
      "Invalid box: (0.49186984, 0.30905405, 0.01678246, 0.20012936)\n",
      "Invalid box: (0.4695432, 0.056146014, 0.035011206, 0.004068236)\n",
      "Invalid box: (0.49048287, 0.34880263, 0.015097461, 0.1258601)\n",
      "Invalid box: (0.029381713, 0.24671952, 0.056440312, 0.032920267)\n",
      "Invalid box: (0.49327993, 0.060700238, 0.013286341, 0.07665949)\n",
      "Invalid box: (0.05136938, 0.16948712, 0.02714786, 0.06776211)\n",
      "Invalid box: (0.07304411, 0.22197522, 0.14229287, 0.07876931)\n",
      "Invalid box: (0.13760452, 0.18146315, 0.14079309, 0.065406494)\n",
      "Invalid box: (0.4963415, 0.03948639, 0.008459822, 0.032773867)\n",
      "Invalid box: (0.48740405, 0.41586557, 0.021385457, 0.2565603)\n",
      "Invalid box: (0.051736344, 0.16906983, 0.031935956, 0.0732068)\n",
      "Invalid box: (0.017392663, 0.2534813, 0.030593177, 0.021161262)\n",
      "Invalid box: (0.033435326, 0.1974751, 0.06483899, 0.13002296)\n",
      "Invalid box: (0.50659513, 0.055762377, 0.028565902, 0.0044139107)\n",
      "Invalid box: (0.23317967, 0.29979128, 0.1819292, 0.0061464696)\n",
      "Invalid box: (0.033132393, 0.19609183, 0.06412208, 0.13007917)\n",
      "Invalid box: (0.16330235, 0.30024892, 0.04551061, 0.0049717375)\n",
      "Invalid box: (0.47556084, 0.7076871, 0.010555378, 0.30528083)\n",
      "Invalid box: (0.18104543, 0.16149613, 0.05567958, 0.026907373)\n",
      "Invalid box: (0.1714878, 0.16664578, 0.06816067, 0.03531006)\n",
      "Invalid box: (0.2682227, 0.29966676, 0.25342807, 0.008897677)\n",
      "Invalid box: (0.4771437, 0.0381667, 0.045667984, 0.03698304)\n",
      "Invalid box: (0.104023404, 0.27206662, 0.20556025, 0.24799038)\n",
      "Invalid box: (0.43143353, 0.21297455, 0.11986641, 0.32268378)\n",
      "Invalid box: (0.47868446, 0.5534046, 0.0083444, 0.16889188)\n",
      "Invalid box: (0.49049494, 0.078761026, 0.006232195, 0.041069712)\n",
      "Invalid box: (0.4809171, 0.6070665, 0.023483077, 0.49891892)\n",
      "Invalid box: (0.6109437, 0.906745, 0.01120732, 0.024503266)\n",
      "Invalid box: (0.47718376, 0.036930785, 0.04603412, 0.03912908)\n",
      "Invalid box: (0.03458311, 0.14380467, 0.063954115, 0.124845654)\n",
      "Invalid box: (0.47846586, 0.5993535, 0.0055917995, 0.08347079)\n",
      "Invalid box: (0.27042633, 0.29974, 0.10852859, 0.0055347816)\n",
      "Invalid box: (0.47871253, 0.5533721, 0.008271551, 0.17312883)\n",
      "Invalid box: (0.47555825, 0.6860075, 0.010187255, 0.2592817)\n",
      "Invalid box: (0.3725678, 0.120972574, 0.18222705, 0.124962635)\n",
      "Invalid box: (0.39447838, 0.3533125, 0.20663728, 0.6015779)\n",
      "Invalid box: (0.2700513, 0.29915133, 0.23177288, 0.0074074343)\n",
      "Invalid box: (0.10875266, 0.10854901, 0.11650606, 0.028592326)\n",
      "Invalid box: (0.5777064, 0.41835773, 0.22597854, 0.72268325)\n",
      "Invalid box: (0.6569252, 0.56954354, 0.06523274, 0.013586309)\n",
      "Invalid box: (0.29927045, 0.111537896, 0.061102957, 0.0063514337)\n",
      "Invalid box: (0.47092548, 0.077222526, 0.012680814, 0.041297484)\n",
      "Invalid box: (0.6479098, 0.573031, 0.04878045, 0.007604387)\n",
      "Invalid box: (0.28499237, 0.05143832, 0.01710586, 0.047504455)\n",
      "Invalid box: (0.46158618, 0.09818193, 0.031218981, 0.0042811385)\n",
      "Invalid box: (0.674438, 0.56851655, 0.0999041, 0.01634268)\n",
      "Invalid box: (0.46925947, 0.071682215, 0.009381806, 0.032369245)\n",
      "Invalid box: (0.31172243, 0.11048664, 0.03569192, 0.0048564263)\n",
      "Invalid box: (0.68466103, 0.76862, 0.014667409, 0.031360798)\n",
      "Invalid box: (0.47216526, 0.08573544, 0.015622062, 0.057503797)\n",
      "Invalid box: (0.34262502, 0.11029406, 0.15066522, 0.008441587)\n",
      "Invalid box: (0.64085835, 0.5735865, 0.036763977, 0.0073822686)\n",
      "Invalid box: (0.3397598, 0.10803608, 0.108498834, 0.009585941)\n",
      "Invalid box: (0.45450568, 0.016997017, 0.013571268, 0.033485867)\n",
      "Invalid box: (0.6834625, 0.76557106, 0.017149802, 0.036392286)\n",
      "Invalid box: (0.27688676, 0.113730535, 0.029451665, 0.004589036)\n",
      "Invalid box: (0.40699282, 0.113438986, 0.02819051, 0.007000748)\n",
      "Invalid box: (0.5025884, 0.18947408, 0.031308364, 0.105819546)\n",
      "Invalid box: (0.28915384, 0.043155506, 0.008884849, 0.03415286)\n",
      "Invalid box: (0.5449583, 0.31946263, 0.12648967, 0.41789055)\n",
      "Invalid box: (0.65608394, 0.673741, 0.07067101, 0.21230555)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# 경로 설정\n",
    "image_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/images\"\n",
    "label_folder = \"C:/Users/fun67/Desktop/lastpj/data/train/labels\"\n",
    "\n",
    "# 두 개의 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 기존 모델 로드\n",
    "model_old = AutoModelForObjectDetection.from_pretrained(\n",
    "    r\"C:\\Users\\fun67\\Desktop\\lastpj\\ckp\\ckpt_rtdetr_r50vd_n98epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# 새로운 모델 로드\n",
    "model_new = AutoModelForObjectDetection.from_pretrained(\n",
    "    r\"C:\\Users\\fun67\\Desktop\\lastpj\\ckp\\ckpt_rtdetr_r50vd_1epoch\"\n",
    ").eval().to(device)\n",
    "\n",
    "# COCO 카테고리 id2label\n",
    "id2label = {0: \"crack\", 1: \"pothole\"}\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def custom_preprocess(image: Image.Image, target_size=(640, 640)):\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))  # 채널을 첫 번째로 (C, H, W) 형식으로 변경\n",
    "    return torch.tensor(image).unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "# YOLO 라벨 파일을 읽어서 경계 상자를 그리기\n",
    "def draw_yolo_labels(image, label_file, id2label):\n",
    "    image_width, image_height = image.size\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, label.split())\n",
    "\n",
    "        # YOLO 형식의 상대 좌표를 절대 좌표로 변환\n",
    "        x_center *= image_width\n",
    "        y_center *= image_height\n",
    "        box_width *= image_width\n",
    "        box_height *= image_height\n",
    "\n",
    "        # 좌상단 (x_min, y_min) 및 우하단 (x_max, y_max) 계산\n",
    "        x_min = x_center - (box_width / 2)\n",
    "        y_min = y_center - (box_height / 2)\n",
    "        x_max = x_center + (box_width / 2)\n",
    "        y_max = y_center + (box_height / 2)\n",
    "\n",
    "        # 빨간색으로 정답 상자 그리기\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=2)\n",
    "        draw.text((x_min, y_min), id2label[int(class_id)], fill=\"red\")\n",
    "\n",
    "# NMS 적용 함수\n",
    "def apply_nms(pred_boxes, pred_scores, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply NMS to the predicted boxes and return the filtered boxes and scores.\n",
    "    pred_boxes: [num_boxes, 4] (x_min, y_min, x_max, y_max)\n",
    "    pred_scores: [num_boxes] Scores for the boxes\n",
    "    iou_threshold: IoU threshold for NMS\n",
    "    \"\"\"\n",
    "    # pred_boxes는 x_min, y_min, x_max, y_max 형식이어야 함\n",
    "    boxes = torch.tensor(pred_boxes)\n",
    "    scores = torch.tensor(pred_scores)\n",
    "\n",
    "    # Apply NMS\n",
    "    keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "\n",
    "    # NMS 이후 선택된 박스와 점수만 반환\n",
    "    nms_boxes = boxes[keep].numpy()\n",
    "    nms_scores = scores[keep].numpy()\n",
    "\n",
    "    return nms_boxes, nms_scores\n",
    "\n",
    "# 모델 예측 상자 그리기 (각 모델마다 다른 색상)\n",
    "# 모델 예측 상자 그리기 (각 모델마다 다른 색상)\n",
    "def draw_predictions(image, pred_boxes, pred_scores, id2label, color=\"blue\", threshold=0.96):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size  # 이미지의 실제 크기 가져오기\n",
    "\n",
    "    for box, score in zip(pred_boxes, pred_scores):\n",
    "        if score > threshold:\n",
    "            # 모델이 반환하는 좌표가 (x_min, y_min, x_max, y_max) 형식이어야 함\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "\n",
    "            # 좌표가 유효한지 확인 (x_min < x_max, y_min < y_max)\n",
    "            if x_min >= x_max or y_min >= y_max:\n",
    "                print(f\"Invalid box: {x_min, y_min, x_max, y_max}\")\n",
    "                continue  # 유효하지 않은 상자는 건너뜀\n",
    "\n",
    "            # 좌표를 이미지 크기로 맞춤\n",
    "            x_min *= image_width\n",
    "            y_min *= image_height\n",
    "            x_max *= image_width\n",
    "            y_max *= image_height\n",
    "\n",
    "            # 상자 그리기\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=2)\n",
    "\n",
    "\n",
    "\n",
    "# 이미지와 라벨 파일 랜덤으로 5개 선택\n",
    "image_files = os.listdir(image_folder)\n",
    "random_files = random.sample(image_files, 5)\n",
    "\n",
    "for image_file_name in random_files:\n",
    "    image_file = os.path.join(image_folder, image_file_name)\n",
    "    label_file_name = image_file_name.replace(\".jpg\", \".txt\")  # 라벨 파일은 같은 이름의 .txt 파일\n",
    "    label_file = os.path.join(label_folder, label_file_name)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    # 이미지 전처리\n",
    "    processed_image = custom_preprocess(image).to(device)\n",
    "\n",
    "    # 기존 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_old = model_old(pixel_values=processed_image)\n",
    "\n",
    "    # 새로운 모델을 사용한 예측\n",
    "    with torch.no_grad():\n",
    "        outputs_new = model_new(pixel_values=processed_image)\n",
    "\n",
    "    # 기존 모델의 예측 경계 상자 및 점수 추출\n",
    "    pred_boxes_old = outputs_old[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores_old = outputs_old[\"logits\"].softmax(-1)[0].cpu().numpy()[:, :-1].max(axis=1)  # 클래스 점수\n",
    "\n",
    "    # 새로운 모델의 예측 경계 상자 및 점수 추출\n",
    "    pred_boxes_new = outputs_new[\"pred_boxes\"][0].cpu().numpy()  # 예측된 경계 상자\n",
    "    pred_scores_new = outputs_new[\"logits\"].softmax(-1)[0].cpu().numpy()[:, :-1].max(axis=1)  # 클래스 점수\n",
    "\n",
    "    # NMS 적용\n",
    "    pred_boxes_old_nms, pred_scores_old_nms = apply_nms(pred_boxes_old, pred_scores_old, iou_threshold=0.9)\n",
    "    pred_boxes_new_nms, pred_scores_new_nms = apply_nms(pred_boxes_new, pred_scores_new, iou_threshold=0.9)\n",
    "\n",
    "    # 정답 상자 그리기 (빨간색, YOLO 형식 라벨)\n",
    "    draw_yolo_labels(image, label_file, id2label)\n",
    "\n",
    "    Vth = 0.92  # threshold 값\n",
    "    # 기존 모델의 예측 상자 그리기 (파란색)\n",
    "    draw_predictions(image, pred_boxes_old_nms, pred_scores_old_nms, id2label, color=\"blue\", threshold=Vth)\n",
    "\n",
    "    # 새로운 모델의 예측 상자 그리기 (초록색)\n",
    "    draw_predictions(image, pred_boxes_new_nms, pred_scores_new_nms, id2label, color=\"green\", threshold=Vth)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
